{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07ba2d6f-5946-483e-b43b-798648e6ba62",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Exploring the in-built tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63998e53-dc72-4a31-8961-2822a017244e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bangalore', 'is', 'the', 'capital', 'of', 'Karnataka', '.']\n",
      "[('Bangalore', 'NNP'), ('is', 'VBZ'), ('the', 'DT'), ('capital', 'NN'), ('of', 'IN'), ('Karnataka', 'NNP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "simpleSentence = \"Bangalore is the capital of Karnataka.\"\n",
    "wordsInSentence =nltk.word_tokenize(simpleSentence)\n",
    "print(wordsInSentence)\n",
    "partsOfSpeechTags = nltk.pos_tag(wordsInSentence)\n",
    "print(partsOfSpeechTags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebeb6391-9db4-423b-a6ac-101ffca207d5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Writing your own tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "accef798-9d15-4f4e-81b9-0a8ca1d75ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learnDefaultTagger(simpleSentence):\n",
    "    wordsInSentence =nltk.word_tokenize(simpleSentence)\n",
    "    tagger = nltk.DefaultTagger(\"NN\")\n",
    "    posEnabledTags = tagger.tag(wordsInSentence)\n",
    "    print(posEnabledTags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "269f3f32-7b9f-4325-8a32-1c5b9f81e0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learnRETagger(simpleSentence):\n",
    "    customPatterns = [\n",
    "        (r'.*ing$', 'ADJECTIVE'),\n",
    "        (r'.*ly$', 'ADVERB'),\n",
    "        (r'.*ion$', 'NOUN'),\n",
    "        (r'(.*ate|.*en|is)$', 'VERB'),\n",
    "        (r'^an$', 'INDEFINITE-ARTICLE'),\n",
    "        (r'^(with|on|at)$', 'PREPOSITION'),\n",
    "        (r'^\\-?[0-9]+(\\.[0-9]+)$', 'NUMBER'),\n",
    "        (r'.*$', None),        \n",
    "    ]\n",
    "    tagger = nltk.RegexpTagger(customPatterns)\n",
    "    wordsInSentence = nltk.word_tokenize(simpleSentence)\n",
    "    posEnabledTags = tagger.tag(wordsInSentence)\n",
    "    print(posEnabledTags)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89fb4a32-7f7a-424f-8ec7-69439d7ef6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learnLookupTagger(simpleSentence):\n",
    "    mapping = {\n",
    "        '.':'.',\n",
    "        'place': 'NN',\n",
    "        'on': 'IN',\n",
    "        'earth': 'NN',\n",
    "        'Mysore' : 'NNP',\n",
    "        'is': 'VBZ',\n",
    "        'an': 'DT',\n",
    "        'amazing': 'JJ'\n",
    "    }\n",
    "    tagger = nltk.UnigramTagger(model = mapping)\n",
    "    wordsInSentence = nltk.word_tokenize(simpleSentence)\n",
    "    posEnabledTags = tagger.tag(wordsInSentence)\n",
    "    print(posEnabledTags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10488ca4-2d69-4cac-823a-33704a7f8ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Mysore', 'NN'), ('is', 'NN'), ('an', 'NN'), ('amazing', 'NN'), ('place', 'NN'), ('on', 'NN'), ('earth', 'NN'), ('.', 'NN'), ('I', 'NN'), ('have', 'NN'), ('visited', 'NN'), ('Mysore', 'NN'), ('10', 'NN'), ('times', 'NN'), ('.', 'NN')]\n",
      "\n",
      "\n",
      "[('Mysore', None), ('is', 'VERB'), ('an', 'INDEFINITE-ARTICLE'), ('amazing', 'ADJECTIVE'), ('place', None), ('on', 'PREPOSITION'), ('earth', None), ('.', None), ('I', None), ('have', None), ('visited', None), ('Mysore', None), ('10', None), ('times', None), ('.', None)]\n",
      "\n",
      "\n",
      "[('Mysore', 'NNP'), ('is', 'VBZ'), ('an', 'DT'), ('amazing', 'JJ'), ('place', 'NN'), ('on', 'IN'), ('earth', 'NN'), ('.', '.'), ('I', None), ('have', None), ('visited', None), ('Mysore', 'NNP'), ('10', None), ('times', None), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "testSentence = \"Mysore is an amazing place on earth. I have visited Mysore 10 times.\"\n",
    "learnDefaultTagger(testSentence)\n",
    "print(\"\\n\")\n",
    "learnRETagger(testSentence)\n",
    "print(\"\\n\")\n",
    "learnLookupTagger(testSentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261ce908-86be-4715-a325-f1ebd3e749e9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Training your own tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca4a54ab-d0b8-4943-83c8-6b73d8587a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53ef418c-495c-4617-b0a6-81aba5a96658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleData():\n",
    "    return [\n",
    "        \"Bangalore is the capital of Karnataka.\",\n",
    "        \"Steve Jobs was the CEO of Apple\",\n",
    "        \"iPhone was Invented by Apple\",\n",
    "        \"Books can be purchased in Market\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64cadf32-68dc-4f75-a62d-0dffd4ac2ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildDictionary():\n",
    "    dict = {}\n",
    "    for sent in sampleData():\n",
    "        partsOfSpeechTags = nltk.pos_tag(nltk.word_tokenize(sent))\n",
    "        for tag in partsOfSpeechTags:\n",
    "            value = tag[0]\n",
    "            pos = tag [1]\n",
    "            dict[value] = pos\n",
    "    return dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e4af342-c7e5-450b-a5a6-a531d2d8e54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveMyTagger(tagger, fileName):\n",
    "    fileHandle = open(fileName, \"wb\")\n",
    "    pickle.dump(tagger, fileHandle)\n",
    "    fileHandle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b29ca44-6937-4f9d-9275-e806ce12786b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveMyTraining(fileName):\n",
    "    tagger = nltk.UnigramTagger(model = buildDictionary())\n",
    "    saveMyTagger(tagger, fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd3fec8d-6e88-4e5f-bde9-70e1bc38ee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadMyTagger(fileName):\n",
    "    return pickle.load(open(fileName, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cbd4ec74-eaea-4171-ba47-080be7f3d708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Iphone', None), ('is', 'VBZ'), ('purchased', 'VBN'), ('by', 'IN'), ('Steve', 'NNP'), ('Jobs', 'NNP'), ('in', 'IN'), ('Bangalore', 'NNP'), ('Market', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "sentence = 'Iphone is purchased by Steve Jobs in Bangalore Market'\n",
    "fileName = 'myTagger.pickle'\n",
    "\n",
    "saveMyTraining(fileName)\n",
    "myTagger = loadMyTagger(fileName)\n",
    "print(myTagger.tag(nltk.word_tokenize(sentence)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ab4872-a6cd-45a1-9fe6-53c53a23da69",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Learning to write your own grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e911e09a-43f5-421e-aa68-53524245bd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.parse.generate import generate\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fc4cfe33-65a9-492c-865c-7edf146ab5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "productions = [\n",
    "    \"ROOT -> WORD\",\n",
    "    \"WORD -> ' '\",\n",
    "    \"WORD -> NUMBER LETTER\",\n",
    "    \"WORD -> LETTER NUMBER\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d45b2ef0-3682-4803-8753-b502fe127996",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = list(string.digits)\n",
    "for digit in digits[:4]:\n",
    "    productions.append(\"NUMBER -> '{w}'\".format(w = digit))\n",
    "\n",
    "letters = \"' | '\".join(list(string.ascii_lowercase[:4]))\n",
    "productions.append(\"LETTER -> '{}'\".format(letters))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0098c1fe-bdbe-43d3-9439-cfbf8aba82bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar with 12 productions (start state = ROOT)\n",
      "    ROOT -> WORD\n",
      "    WORD -> ' '\n",
      "    WORD -> NUMBER LETTER\n",
      "    WORD -> LETTER NUMBER\n",
      "    NUMBER -> '0'\n",
      "    NUMBER -> '1'\n",
      "    NUMBER -> '2'\n",
      "    NUMBER -> '3'\n",
      "    LETTER -> 'a'\n",
      "    LETTER -> 'b'\n",
      "    LETTER -> 'c'\n",
      "    LETTER -> 'd'\n"
     ]
    }
   ],
   "source": [
    "grammarString = \"\\n\".join(productions)\n",
    "grammar = nltk.CFG.fromstring(grammarString)\n",
    "print(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "73324395-9737-4072-bff5-8c3385f506c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Word:  , size : 0\n",
      "Generated Word: 0a , size : 2\n",
      "Generated Word: 0b , size : 2\n",
      "Generated Word: 0c , size : 2\n",
      "Generated Word: 0d , size : 2\n"
     ]
    }
   ],
   "source": [
    "for sentence in generate(grammar, n=5, depth = 5):\n",
    "    palindrome = \"\".join(sentence).replace(\" \", \"\")\n",
    "    print(\"Generated Word: {} , size : {}\".format(palindrome,len(palindrome)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38aec65c-5a5d-4120-812f-4d66f3e74825",
   "metadata": {},
   "source": [
    "### Writing a probabilistic CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8e475ece-7366-4135-80d2-6a7a0df17456",
   "metadata": {},
   "outputs": [],
   "source": [
    "productions = [\n",
    "    \"ROOT -> WORD [1.0]\",\n",
    "    \"WORD -> P1 [0.25]\",\n",
    "    \"WORD -> P1 P2 [0.25]\",\n",
    "    \"WORD -> P1 P2 P3 [0.25]\",\n",
    "    \"WORD -> P1 P2 P3 P4 [0.25]\",\n",
    "    \"P1 -> 'A' [1.0]\",\n",
    "    \"P2 -> 'B' [0.5]\",\n",
    "    \"P2 -> 'C' [0.5]\",\n",
    "    \"P3 -> 'D' [0.3]\",\n",
    "    \"P3 -> 'E' [0.3]\",\n",
    "    \"P3 -> 'F' [0.4]\",\n",
    "    \"P4 -> 'G' [0.9]\",\n",
    "    \"P4 -> 'H' [0.1]\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "834b94fb-3965-4eb2-b9de-71ec78d3f71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar with 13 productions (start state = ROOT)\n",
      "    ROOT -> WORD [1.0]\n",
      "    WORD -> P1 [0.25]\n",
      "    WORD -> P1 P2 [0.25]\n",
      "    WORD -> P1 P2 P3 [0.25]\n",
      "    WORD -> P1 P2 P3 P4 [0.25]\n",
      "    P1 -> 'A' [1.0]\n",
      "    P2 -> 'B' [0.5]\n",
      "    P2 -> 'C' [0.5]\n",
      "    P3 -> 'D' [0.3]\n",
      "    P3 -> 'E' [0.3]\n",
      "    P3 -> 'F' [0.4]\n",
      "    P4 -> 'G' [0.9]\n",
      "    P4 -> 'H' [0.1]\n"
     ]
    }
   ],
   "source": [
    "grammarString = '\\n'.join(productions)\n",
    "grammar = nltk.PCFG.fromstring(grammarString)\n",
    "print(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9b414bf9-dbda-4350-a741-a849711bef41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Word: A , size : 1\n",
      "Generated Word: AB , size : 2\n",
      "Generated Word: AC , size : 2\n",
      "Generated Word: ABD , size : 3\n",
      "Generated Word: ABE , size : 3\n",
      "Generated Word: ABF , size : 3\n",
      "Generated Word: ACD , size : 3\n",
      "Generated Word: ACE , size : 3\n",
      "Generated Word: ACF , size : 3\n",
      "Generated Word: ABDG , size : 4\n"
     ]
    }
   ],
   "source": [
    "for sentence in generate(grammar, n=10, depth = 5):\n",
    "    palindrome = \"\".join(sentence).replace(\" \", \"\")\n",
    "    print(\"Generated Word: {} , size : {}\".format(palindrome,len(palindrome)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7039867f-b0cd-49b5-8105-32f4a9a4fa63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
