{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "860c424d-5e2c-45e1-8bef-a895b1e3a558",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Using inbuilt NERs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52274ab0-3c7d-4850-8781-643c30b2cb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce3202f5-d855-4ef8-96ab-34d1fd28c507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleNE():\n",
    "    sent = nltk.corpus.treebank.tagged_sents()[0]\n",
    "    print(nltk.ne_chunk(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c57a46-c2e8-4088-9554-6f48bb402c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleNE2():\n",
    "    sent = nltk.corpus.treebank.tagged_sents()[0]\n",
    "    print(nltk.ne_chunk(sent, binary = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e38afee-7b62-4bcb-9845-5d1a93b0c130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (PERSON Pierre/NNP)\n",
      "  (ORGANIZATION Vinken/NNP)\n",
      "  ,/,\n",
      "  61/CD\n",
      "  years/NNS\n",
      "  old/JJ\n",
      "  ,/,\n",
      "  will/MD\n",
      "  join/VB\n",
      "  the/DT\n",
      "  board/NN\n",
      "  as/IN\n",
      "  a/DT\n",
      "  nonexecutive/JJ\n",
      "  director/NN\n",
      "  Nov./NNP\n",
      "  29/CD\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "sampleNE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e510f452-6ba4-4bd6-b794-fc8ef315db1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NE Pierre/NNP Vinken/NNP)\n",
      "  ,/,\n",
      "  61/CD\n",
      "  years/NNS\n",
      "  old/JJ\n",
      "  ,/,\n",
      "  will/MD\n",
      "  join/VB\n",
      "  the/DT\n",
      "  board/NN\n",
      "  as/IN\n",
      "  a/DT\n",
      "  nonexecutive/JJ\n",
      "  director/NN\n",
      "  Nov./NNP\n",
      "  29/CD\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "sampleNE2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b60d6e-7d2a-4f58-9385-c4dff0baf6c2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Creating, inversing, and using dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67162b5b-a245-4d7a-a3b7-15cd0b501729",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningDictionary():\n",
    "    def __init__(self,sentence):\n",
    "        self.words = nltk.word_tokenize(sentence)\n",
    "        self.tagged = nltk.pos_tag(self.words)\n",
    "        self.buildDictionary()\n",
    "        self.buildReverseDictionary()\n",
    "        \n",
    "    def buildDictionary(self):\n",
    "        self.dictionary = {}\n",
    "        for (word,pos) in self.tagged:\n",
    "            self.dictionary[word] = pos\n",
    "    \n",
    "    def buildReverseDictionary(self):\n",
    "        self.rdictionary = {}\n",
    "        for key in self.dictionary.keys():\n",
    "            value = self.dictionary[key]\n",
    "            if value not in self.rdictionary:\n",
    "                self.rdictionary[value] = [key]\n",
    "            else:\n",
    "                self.rdictionary[value].append(key)\n",
    "    \n",
    "    def isWordPresent(self,word):\n",
    "        return 'Yes' if word in self.dictionary else 'No'\n",
    "    \n",
    "    def getPOSForWord(self,word):\n",
    "        return self.dictionary[word] if word in self.dictionary else None\n",
    "\n",
    "    def getWordsForPos(self, pos):\n",
    "        return self.rdictionary[pos] if pos in self.rdictionary else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74d45ab6-180c-44a5-9e47-8ea22c958e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"All the flights got delayed due to bad weather\"\n",
    "learning = LearningDictionary(sentence)\n",
    "words = [\"chair\", \"flights\", \"delayed\", \"pencil\", \"weather\"]\n",
    "pos = [\"NN\",\"VBS\", \"NNS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02ac9cee-10bb-4279-b92b-f8754e5cd14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is 'chair' present in dictionary? : 'No'\n",
      "\n",
      "\n",
      "Is 'flights' present in dictionary? : 'Yes'\n",
      "\tPOS for 'flights' is NNS\n",
      "\n",
      "\n",
      "Is 'delayed' present in dictionary? : 'Yes'\n",
      "\tPOS for 'delayed' is VBN\n",
      "\n",
      "\n",
      "Is 'pencil' present in dictionary? : 'No'\n",
      "\n",
      "\n",
      "Is 'weather' present in dictionary? : 'Yes'\n",
      "\tPOS for 'weather' is NN\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    status = learning.isWordPresent(word)\n",
    "    print(\"Is '{}' present in dictionary? : '{}'\".format(word,status))\n",
    "    if status == 'Yes':\n",
    "        print(\"\\tPOS for '{}' is {}\".format(word, learning.getPOSForWord(word)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc568d96-1ea0-41bf-9ea6-38f54996e553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS 'NN' has '['weather']' words\n",
      "POS 'VBS' has 'None' words\n",
      "POS 'NNS' has '['flights']' words\n"
     ]
    }
   ],
   "source": [
    "for pword in pos:\n",
    "    print(\"POS '{}' has '{}' words\".format(pword,learning.getWordsForPos(pword)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c069da-dd9b-4ab5-bd3e-6ef741fc1814",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Choosing the feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a408cd46-93d4-477d-b9a2-12d74d9341df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77b2a57d-135a-4cb6-8d33-c28a397b6024",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampledata =[\n",
    "    ('KA-01-F 1034 A' , 'rtc'),\n",
    "    ('KA-02-F 1030 B' , 'rtc'),\n",
    "    ('KA-03-FA 1200 C' , 'rtc'),\n",
    "    ('KA-01-G 0001 A' , 'gov'),\n",
    "    ('KA-02-G 1004 A' , 'gov'),\n",
    "    ('KA-03-G 0204 A' , 'gov'),\n",
    "    ('KA-04-G 9230 A' , 'gov'),\n",
    "    ('KA-27-F 1290' , 'oth')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ab970f7-3dd4-4c0f-81eb-511e58204241",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(sampledata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e465024-863f-4d98-9a0a-3748a1626d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata =[\n",
    "    'KA-01-G 0109',\n",
    "    'KA-02-F 9020 AC',\n",
    "    'KA-02-FA 0801',\n",
    "    'KA-01 9129'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2bf6b54-8291-479a-8aa6-742fc6ac3636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learnSimpleFeatures():\n",
    "    def vehicleNumberFeature(vnumber):\n",
    "        return {'vehicle_class': vnumber[6]}\n",
    "    featuresets = [(vehicleNumberFeature(vn), cls) for (vn,cls) in sampledata]\n",
    "    classifier = nltk.NaiveBayesClassifier.train(featuresets)\n",
    "    for num in testdata:\n",
    "        feature = vehicleNumberFeature(num)\n",
    "        print(\"(simple) %s is of type %s\" %(num, classifier.classify(feature)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6dcb0e21-36c8-4223-841a-02033482ca2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learnFeatures():\n",
    "    def vehicleNumberFeature(vnumber):\n",
    "        return{\n",
    "            'vehicle_class' : vnumber[6],\n",
    "            'vehicle_prev': vnumber[5]\n",
    "        }\n",
    "    featuresets = [(vehicleNumberFeature(vn), cls) for (vn,cls) in sampledata]\n",
    "    classifier = nltk.NaiveBayesClassifier.train(featuresets)\n",
    "    for num in testdata:\n",
    "        feature = vehicleNumberFeature(num)\n",
    "        print(\"(dual) %s is of type %s\" %(num, classifier.classify(feature)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a7748bb-6178-4812-9bc6-8e1d22a738ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({'vehicle_class': 'F'}, 'rtc'), ({'vehicle_class': 'G'}, 'gov'), ({'vehicle_class': 'G'}, 'gov'), ({'vehicle_class': 'F'}, 'rtc'), ({'vehicle_class': 'G'}, 'gov'), ({'vehicle_class': 'F'}, 'oth'), ({'vehicle_class': 'F'}, 'rtc'), ({'vehicle_class': 'G'}, 'gov')]\n",
      "(simple) KA-01-G 0109 is of type gov\n",
      "(simple) KA-02-F 9020 AC is of type rtc\n",
      "(simple) KA-02-FA 0801 is of type rtc\n",
      "(simple) KA-01 9129 is of type gov\n"
     ]
    }
   ],
   "source": [
    "learnSimpleFeatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46699e38-672c-44f8-8096-5818e8ea27dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(dual) KA-01-G 0109 is of type gov\n",
      "(dual) KA-02-F 9020 AC is of type rtc\n",
      "(dual) KA-02-FA 0801 is of type rtc\n",
      "(dual) KA-01 9129 is of type oth\n"
     ]
    }
   ],
   "source": [
    "learnFeatures()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524b1861-626b-4a6e-b517-836b933a5346",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Segmenting sentences using classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3d5d02a9-52f6-4173-bedf-a4213a9f748e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureExtractor(words, i):\n",
    "    return({'current-word': words[i],\n",
    "           'next-is-upper': words[i+1][0].isupper()}, words[i+1][0].isupper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b18c9c10-6566-4314-ad27-6ec038fc988b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeaturessets(sentence):\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    featuresets = [featureExtractor(words, i) for i in range(1,len(words)-1) if words[i] == '.']\n",
    "    return featuresets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "72fc6702-6a99-4627-9b52-30d4a89e2dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentTextAndPrintSentences(data):\n",
    "    words = nltk.word_tokenize(data)\n",
    "    for i in range(0, len(words)-1):\n",
    "        if words[i] == '.':\n",
    "            if classifier.classify(featureExtractor(words, i)[0]) == True:\n",
    "                print(\".\")\n",
    "            else:\n",
    "                print(words[i], end = ' ')\n",
    "        else:\n",
    "            print(\"{}\".format(words[i]), end = ' ')\n",
    "    print(words[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "da5ba904-dd3c-4e0c-b34b-2dabc2ec204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = \"India, officially the Republic of India (Bhārat Gaṇarājya),[e] is a country in South Asia. it is the seventh-largest country by area, the second-most populous country (with over 1.2 billion people), and the most populous democracy in the world. It is bounded by the Indian Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast. It shares land borders with Pakistan to the west;[f] China, Nepal, and Bhutan to the northeast; and Myanmar (Burma) and Bangladesh to the east. In the Indian Ocean, India is in the vicinity of Sri Lanka and the Maldives. India's Andaman and Nicobar Islands share a maritime border with Thailand and Indonesia.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "61df2e1d-3e66-4eb9-99e5-e8d0081a32a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = \"The Indian subcontinent was home to the urban Indus Valley Civilisation of the 3rd millennium BCE. In the following millennium, the oldest scriptures associated with Hinduism began to be composed. Social stratification, based on caste, emerged in the first millennium BCE, and Buddhism and Jainism arose. Early political consolidations took place under the Maurya and Gupta empires; the later peninsular Middle Kingdoms influenced cultures as far as southeast Asia. In the medieval era, Judaism, Zoroastrianism, Christianity, and Islam arrived, and Sikhism emerged, all adding to the region's diverse culture. Much of the north fell to the Delhi sultanate; the south was united under the Vijayanagara Empire. The economy expanded in the 17th century in the Mughal Empire. In the mid-18th century, the subcontinent came under British East India Company rule, and in the mid-19th under British crown rule. A nationalist movement emerged in the late 19th century, which later, under Mahatma Gandhi, was noted for nonviolent resistance and led to India's independence in 1947.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b5e072c7-81d7-40e6-8b3f-1727f5d28064",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataset = getFeaturessets(traindata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "afe5fd29-06cc-4518-81f5-8def87e9beb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(traindataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cdf10ff3-5520-456d-bb67-933594a85068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Indian subcontinent was home to the urban Indus Valley Civilisation of the 3rd millennium BCE .\n",
      "In the following millennium , the oldest scriptures associated with Hinduism began to be composed .\n",
      "Social stratification , based on caste , emerged in the first millennium BCE , and Buddhism and Jainism arose .\n",
      "Early political consolidations took place under the Maurya and Gupta empires ; the later peninsular Middle Kingdoms influenced cultures as far as southeast Asia .\n",
      "In the medieval era , Judaism , Zoroastrianism , Christianity , and Islam arrived , and Sikhism emerged , all adding to the region 's diverse culture .\n",
      "Much of the north fell to the Delhi sultanate ; the south was united under the Vijayanagara Empire .\n",
      "The economy expanded in the 17th century in the Mughal Empire .\n",
      "In the mid-18th century , the subcontinent came under British East India Company rule , and in the mid-19th under British crown rule .\n",
      "A nationalist movement emerged in the late 19th century , which later , under Mahatma Gandhi , was noted for nonviolent resistance and led to India 's independence in 1947 .\n"
     ]
    }
   ],
   "source": [
    "segmentTextAndPrintSentences(testdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157f8942-ecfe-4132-8951-f71e4ac68a13",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Classifying documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f8d45173-818e-4930-952a-cc87c3416680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b5435339-9454-47c7-aff6-ee29dd51493c",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = {\n",
    "    'mlb': 'https://sports.yahoo.com/mlb/rss.xml',\n",
    "    'nfl': 'https://sports.yahoo.com/nfl/rss.xml'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "698aa2fc-4ca5-47be-ba8d-9fdf97c71b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "feedmap = {}\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e29c2414-a454-420a-9701-7ba81a76bb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureExtractor(words):\n",
    "    features = {}\n",
    "    for word in words:\n",
    "        if word not in stopwords:\n",
    "            features[\"word({})\".format(word)] = True\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "60a5ecb3-e16a-458c-9af3-9e4ab6709448",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4b9d7a51-a932-4fe5-8835-57d2dd0bd4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading https://sports.yahoo.com/mlb/rss.xml\n",
      "downloading https://sports.yahoo.com/nfl/rss.xml\n"
     ]
    }
   ],
   "source": [
    "for category in urls.keys():\n",
    "    feedmap[category] = feedparser.parse(urls[category])\n",
    "    print(\"downloading {}\".format(urls[category]))\n",
    "    for entry in feedmap[category]['entries']:\n",
    "        data = entry['summary']\n",
    "        words = data.split()\n",
    "        sentences.append((category,words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "82531ae6-4195-42bc-9804-dbe2eaba3752",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(featureExtractor(words), category) for category, words in sentences]\n",
    "random.shuffle(featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f088834e-598a-4916-9443-627988c0147f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(featuresets)\n",
    "off = total // 2\n",
    "trainset = featuresets[off:]\n",
    "testset = featuresets[:off]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ab466025-4a12-469c-a67a-1bd75df2f06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d0621bb8-345b-48ba-b5c9-29f254bbeb40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8823529411764706\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier,testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "369d359a-9530-4c7c-8927-10afb58d13a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "            word(Eagles) = True              nfl : mlb    =     14.0 : 1.0\n",
      "             word(Aaron) = True              mlb : nfl    =      7.4 : 1.0\n",
      "               word(NFL) = True              nfl : mlb    =      6.4 : 1.0\n",
      "              word(2022) = True              nfl : mlb    =      5.3 : 1.0\n",
      "           word(season.) = True              nfl : mlb    =      5.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fb36b690-ec59-4daa-b271-b9da4ddb98bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nfl -> Philadelphia came out flat as a two-touchdown favorite in Houston, but it pulled away in the second half behind a dominant defense to improve to 8-0.\n",
      "mlb -> On this week's Bears Wire podcast, we discuss how Ryan Poles' moves at the trade deadline show he's prioritizing Justin Fields.\n",
      "nfl -> As we enter Week 9, the midpoint of the season provides a checkpoint for those first-half surprises – from the good, to the bad, to the ugly.\n",
      "nfl -> Coming off their loss to the San Francisco 49ers, the Rams face another stiff test against Tom Brady and the Tampa Bay Buccaneers. Who's the favorite?\n"
     ]
    }
   ],
   "source": [
    "for (i,entry) in enumerate(feedmap['nfl']['entries']):\n",
    "    if i < 4:\n",
    "        features = featureExtractor(entry['title'].split())\n",
    "        category = classifier.classify(features)\n",
    "        print('{} -> {}'.format(category, entry['summary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e4937622-155f-484d-bd62-5953dc9d23a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlb -> Justin Verlander finally earned his first World Series victory as Houston held on for a 3-2 win in Philadelphia. The Astros are going home with a 3-2 lead in the series.\n",
      "mlb -> Justin Verlander's teammates gave him the rookie treatment after the game and doused him with all sorts of stuff after his first Fall Classic win.\n",
      "mlb -> Albert Pujols is set to fulfill his personal-services contract with the Angels. What does that mean for the Angels and his association with the Cardinals?\n",
      "mlb -> Justin Verlander, Jeremy Peña could be forever linked in Astros' history after leading Houston to a Game 5 win vs. the Phillies.\n"
     ]
    }
   ],
   "source": [
    "for (i,entry) in enumerate(feedmap['mlb']['entries']):\n",
    "    if i < 4:\n",
    "        features = featureExtractor(entry['title'].split())\n",
    "        category = classifier.classify(features)\n",
    "        print('{} -> {}'.format(category, entry['summary']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c4c0ed-2219-41de-9350-c477768e63cd",
   "metadata": {},
   "source": [
    "### Writing a POS tagger with context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0d67a506-f6d9-4b7e-a15c-a7482f65e8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "\"What is your address when you're in Bangalore?\",\n",
    "\"the president's address on the state of the economy.\",\n",
    "\"He addressed his remarks to the lawyers in the audience.\",\n",
    "\"In order to address an assembly, we should be ready\",\n",
    "\"He laughed inwardly at the scene.\",\n",
    "\"After all the advance publicity, the prizefight turned out to be a laugh.\",\n",
    "\"We can learn to laugh a little at even our most serious foibles.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "14b23737-0502-44a1-9c04-26942dc3afe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentenceWords():\n",
    "    sentwords = []\n",
    "    for sentence in sentences:\n",
    "        words = nltk.pos_tag(nltk.word_tokenize(sentence))\n",
    "        sentwords.append(words)\n",
    "    return sentwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "08c7eda7-d835-4a00-93d1-f59c05d97dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noContextTagger():\n",
    "    tagger = nltk.UnigramTagger(getSentenceWords())\n",
    "    print(tagger.tag('the little remarks towards assembly are laughable'.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "24ba4a0f-c9c7-477d-901a-a40434834881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def withContextTagger():\n",
    "    def wordFeatures(words, wordPosInSentence):\n",
    "        endFeatures = {\n",
    "            'last(1)': words[wordPosInSentence][-1],\n",
    "            'last(2)': words[wordPosInSentence][-2:],\n",
    "            'last(3)': words[wordPosInSentence][-3:],\n",
    "        }\n",
    "        if wordPosInSentence > 1:\n",
    "            endFeatures['prev'] = words[wordPosInSentence - 1]\n",
    "        else:\n",
    "            endFeatures['prev'] = '|NONE|'\n",
    "        return endFeatures\n",
    "    allsentences = getSentenceWords()\n",
    "    featureddata = []\n",
    "    for sentence in allsentences:\n",
    "        untaggedSentence = nltk.tag.untag(sentence)\n",
    "        featuredsentence = [(wordFeatures(untaggedSentence, index), tag) for\n",
    "        index, (word, tag) in enumerate(sentence)]\n",
    "        featureddata.extend(featuredsentence)\n",
    "    breakup = int(len(featureddata) * 0.5)\n",
    "    traindata = featureddata[breakup:]\n",
    "    testdata = featureddata[:breakup]\n",
    "    classifier = nltk.NaiveBayesClassifier.train(traindata)\n",
    "    print(\"Accuracy of the classifier : {}\".format(nltk.classify.accuracy(classifier, testdata)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "379e60c6-35cf-4a64-8578-49511f820727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 'DT'), ('little', 'JJ'), ('remarks', 'NNS'), ('towards', None), ('assembly', 'NN'), ('are', None), ('laughable', None)]\n"
     ]
    }
   ],
   "source": [
    "noContextTagger()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b49581fd-52e8-4341-a42b-f4f0b5110bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the classifier : 0.46153846153846156\n"
     ]
    }
   ],
   "source": [
    "withContextTagger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee65273-0afc-4ee3-b4a0-c234462d9f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
